#!/usr/bin/env python
import os, sys, argparse, glob
import datetime as DT
import netCDF4 as nc4
import numpy as np
import matplotlib as plt
from mpl_toolkits.basemap import Basemap, shiftgrid,cm
from matplotlib.colors import LinearSegmentedColormap

sys.path.append('/home/rpernak/revised_python_libraries')
import utils

# constants
Mwa = 28.96E-3 	# molecular weight of dry air (kg mol-1)
R 	= 8.31
Av 	= 6.022E23 # molec/mol
DU_moleccm2_cf = 2.69E16 # 1 DU = 2.69E16 molec/cm2
mtocm_cf = 100.; ppm_cf = 1.E-6; m3_to_cm3_cf = 1.E-6
calNexRetDir = \
  '/nas/project/p1913/cris_cal_2012_june_11_june_30/cdf_dir/'

def makeRetList(retPath=calNexRetDir, outFile='retrieval_dates.txt', \
  retPrefix='retv_vars.'):
  """
  Make an ASCII list of dates associated with all retrievals in 
  retPath

  Call
    makeRetList()

  Input
    None required

  Output
    None, but output is written to outFile (see keywords)

  Keywords
    retPath -- string, path to directory that contains retrievals 
      files
    retPrefix -- string, prefix that will be used with retPath in an 
      "ls" to find retrievals 
    outFile -- string, path to which date strings of retrievals 
      will be written
  """

  retrievals = glob.glob('%s/retv_vars.*' % retPath)
  nRet = len(retrievals)
  outFP = open(outFile, 'w')
  for iRet, ret in enumerate(retrievals):
    print 'Processing %d of %d' % (iRet, nRet)
    ncObj = nc4.Dataset(ret, 'r')
    retDate = str(ncObj.getncattr('Date'))
    outFP.write('%s %s\n' % (retrievals[iRet], retDate))
  # end loop over retrievals
  outFP.close()

  return True
# end makeRetList()

def getRetData(inDate, retsDates='retrieval_dates.txt'):
  """
  Find and extract data from retrievals in retPath

  Call
    retDict = getRetData(inDate)

  Input
    inDate -- string, YYYYMMDD date of interest

  Output
    retDict -- dictionary with keys (and associated arrays) for 
      retrieval latitudes, longitudes, pressures, retrieval filenames,
      retrieval concentrations, apriori concentrations, averaging 
      kernel, weighting function, and total column amount

  Keywords
    retsDates -- string, path to file generated by makeRetList() or 
      a file that follows the same listing convention (YYYYMMDD for 
      each retrieval)
  """

  print 'Getting retrievals...'

  retrievals, retDates = np.loadtxt(retsDates, dtype=str, unpack=True)
  iMatch = np.where(retDates == inDate)[0]
  nMatch = iMatch.size
  if nMatch == 0: return None

  retrievals = retrievals[iMatch]
  attrVar = np.array(['Date', 'Quality_Flag', 'rvmr', 'pressure', \
    'rvmr_wgt', 'xretv', 'xa', 'avg_kernel', 'tot_col'])

  # retrieval returned variables: initialize lists
  retList, retLat, retLon, pRet, wgtJPL, retrieved, apriori, \
    rvmrRet, avgKernel, totCol = ([] for i in range(10))

  for iRet, ret in enumerate(retrievals):
    print '%s, %d of %d' % (os.path.basename(ret), iRet+1, nMatch)
    ncObj = nc4.Dataset(ret, 'r')

    # ensure retrieval has all necessary attributes
    retAttrs = ncObj.ncattrs()
    retVars = ncObj.variables.keys()
    attrVarRet = np.array(retAttrs + retVars)
    if not np.all(np.in1d(attrVar, attrVarRet)): 
      continue
      ncObj.close()
    # end var/att check

    retList.append(ret)
    qFlag = int(ncObj.getncattr('Quality_Flag'))

    # representative volume mixing ratio (ppmv)
    rvmrRet.append(np.array(ncObj.variables['rvmr']) * 1e3)

    # lat/lon of retrieval, ~15 pressure (mbar) levels
    retLat.append(float(ncObj.getncattr('Latitude')))
    retLon.append(float(ncObj.getncattr('Longitude')))
    pRet.append(np.array(ncObj.variables['pressure']))

    # JPL weighting function
    wgtJPL.append(np.array(ncObj.variables['rvmr_wgt']) * 1e3)

    # retrieved species concentrations (ppmv)
    retrieved.append(np.array(ncObj.variables["xretv"]) * 1e3)

    # A priori concentration (ppmv)
    apriori.append(np.array(ncObj.variables["xa"]) * 1e3)

    # averaging kernel
    avgKernel.append(np.array(ncObj.variables["avg_kernel"]) * 1e3)

    # total column (mol/cm2)
    totCol.append(np.array(ncObj.variables["tot_col"][0]))
    ncObj.close()
  # end ret loop

  retDict = {'filenames': np.array(retList), \
    'lats': np.array(retLat), 'lons': np.array(retLon), \
    'pressure': np.array(pRet), 'weight_func': np.array(wgtJPL), \
    'ret_conc': np.array(retrieved), 'apr_conc': np.array(apriori), \
    'avg_kern': np.array(avgKernel), 'total_col': np.array(totCol), \
    'RVMR': np.array(rvmrRet)}

  return retDict
# end getRetData()

def getMETCRO(inFile):
  """
  METCRO...

  Call

  Input
    inFile -- string, METCRO file full path

  Output
    metcroDict -- dictionary with keys and associated arrays for 
      pressure, mass densities, temperatures, heights, and flags

  Keywords
  """

  print 'Getting METCRO data...'

  ncObj = nc4.Dataset(inFile,'r')

  press_level = np.array(ncObj.variables["PRES"])  # pressure (Pa)
  dens = np.array(ncObj.variables["DENS"])  # kg/m3
  ta = np.array(ncObj.variables["TA"])*100. # K
  zf = np.array(ncObj.variables["ZF"]) # meters above ground
  tStep = np.array(ncObj.variables["TFLAG"])

  ncObj.close()

  metcroDict = {'pressure': press_level, 'density': dens, \
    'temperature': ta, 'altitude': zf, 'flag': tStep}

  return metcroDict
# end getMETCRO()

def getConcentration(inFile, mol='NH3'):
  """
  Extract concentration array for a given molecule from a netCDF file
    (originally for NH3 in ppm)

  Call

  Input
    inFile -- string, concentration file full path

  Output
    concentration -- 4-D float array of molecule concentration

  Keywords
    mol -- string, name/formula of molecule (e.g. NH3)
  """

  print 'Getting concentration data...'
  ncObj = nc4.Dataset(inFile,'r')
  con = np.array(ncObj.variables[mol]) * 1000
  ncObj.close()

  return con
# end getConcentration()

def getGrid(inFile):
  """
  Extract latitudes and longitudes from a grid file

  Call

  Input
    inFile -- string, grid file full path

  Output
    lats, lons -- float arrays of geographical coordinates

  Keywords
  """

  print 'Getting grid points...'
  ncObj = nc4.Dataset(inFile,'r')
  lats = np.array(ncObj.variables["LAT"])
  lons = np.array(ncObj.variables["LON"])
  ncObj.close()

  return lats, lons
# end getGrid

def closestGridBox(lat, lon, rLAT, rLON, maxCut=10000.0):
  """
  Calculate closest grid box to retrieval coordinate

  Call

  Input
    lat, lon -- float arrays, 4D that correspond to getConcentration 
      array
    rLAT, rLON -- floats, retrieval coordinates

  Output
    iRow, iCol -- integers, row and column index of closest grit point

    for indexing, this would be :
      lat[0, 0, iRow, iCol]
      lon[0, 0, iRow, iCol]

  Keywords
    maxCut -- float, maximum allowed difference between grid and 
      retrieval points
  """

  aDiff = abs(lat[0, 0, :, :] - rLAT) + abs(lon[0, 0, :, :] - rLON)
  iRow, iCol = np.unravel_index(aDiff.argmin(), aDiff.shape)

  return iRow, iCol
# end closestGridBox()

def getModelParams(idxRow, idxCol, concentration, \
  metcroDict, time_index=14):
  """
  Extract model parameters for grid points closest to retrieval 
  locations

  Call
    modelDict = \
      cc.getModelParams(idxRow, idxCol, concentration, metrcoDict)

  Input
    idxRow, idxCol -- float arrays, vectors with indices to closest 
      grid point to given retrieval location
    concentration -- float array, 4D matrix from getConcentration
    metcroDict -- dictionary from getMETCRO()

  Keywords
    time_index -- int, local time hour (1-24) for which pressures and
      concentrations will be extracted. By default, this is 14 because
      CrIS flies over California around 1430

  Output
    modelDict -- dictionary with model 'pressure' and 
      'concentration' key/value pairs

  """

  modelConcentration = \
    np.array(concentration[time_index, :, idxRow, idxCol])

  # convert from Pa to mbar
  modelP = metcroDict['pressure'][time_index , :, idxRow, idxCol] / \
    100.0

  modelDict = {'pressure': modelP, 'concentration': modelConcentration}

  return modelDict
# end getModelParams()

def interpModel2Retrieval(rPressure, mPressure, mConcentration):
  """
  Interpolate model pressures and concentrations to retrieval "grid"

  Call
    mInterp = \
      interpModel2Retrieval(rPressure, mPressure, mConcentration)

  Input
    rPressure -- float array, retrieval pressure levels
      nColumns x nLevels, where nColumns is the number of grid points 
      and nLevels is the number of vertical pressure levels as 
      defined by the retrievals
    mPressure -- float array, model pressure levels
      nColumns x nLevels, where nColumns is the number of grid points 
      and nLevels is the number of vertical pressure levels as 
      defined by the model
    mConcentration -- float array, model concentrations
      nColumns x nLevels, where nColumns is the number of grid points 
      and nLevels is the number of vertical pressure levels as 
      defined by the model

  Output
    mInterp -- float array, model concentrations interpolated from 
      model pressure levels to retrieval pressure levels 
      (rPressure dimensions)

  """

  mInterp = []
  for iCol, col in enumerate(rPressure):
    # thinking of doing a linear polyfit instead of interpolation 
    # so extrapolation is also done when necessary
    coeff = np.polyfit(mPressure[iCol], mConcentration[iCol], 1)
    poly = np.poly1d(coeff)
    mInt = poly(col)
    mInterp.append(mInt)
  # end loop over columns 

  return np.array(mInterp)
# end interpModel2Retrieval()

def calcModelRVMR(inRetDict, modelX):
  """
  Calculate representative VMR (at surface?) using the retrieval 
  observational operator

  Call
    modRVMR, retRVMR = calcModelRVMR(inRetDict, modelX)

  Input
    inRetDict -- dictionary, generated with getRetData()
    modelX -- float array, model concentrations interpolated onto 
      retrieval pressures (i.e., interpModel2Retrieval() output)

  Output
    modRVMR, retRVMR -- float arrays, representative VMR at the 
      surface from the model and retrieval data
  """

  # apriori x, averaging kernel, representative VMR, concentration
  # for retrievals
  retXa = inRetDict['apr_conc']
  retA = inRetDict['avg_kern']
  allRetRVMR = inRetDict['RVMR']
  retX = inRetDict['ret_conc']

  modRVMR = []; retRVMR = []
  for iRow, row in enumerate(retXa):
    retSfcRVMR = allRetRVMR[iRow, 0]

    # model-apriori difference
    xmaDiff = np.log(modelX[iRow]) - np.log(row)

    # model retrieved x
    xModRet = np.exp(np.log(iRow)) + np.dot(retA[iRow], xmaDiff)

    # mapping matrix (weird dimensions...)
    W = inRetDict['weight_func'][iRow, 0]
    rvmr = np.exp(np.dot(W, np.log(retX[iRow])))

    # not sure why we're taking the surface RVMR
    if retSfcRVMR < 500.0:
      sfcMod = rvmr; sfcRet = retSfcRVMR
    else:
      sfcMod = np.nan; sfcRet = np.nan
    # end retSfcRVMR

    modRVMR.append(sfcMod)
    retRVMR.append(sfcRet)
  # end loop over columns

  return np.array(modRVMR), np.array(retRVMR)
# end calcModelRVMR()

def getVarsModRet(fileDict):
  """
  Using the files in fileDict, extract model output and retrieval 
  data and return them as arrays in a dictionary. the dictionary is 
  saved in a .npz (compressed NumPy) file

  Call
    varDict = getVarsModRet(fileDict)

  Input
    fileDict -- dictionary with 'grid', 'metcro', 'conc', 'retrievals',
      'out', and 'model_date' keys (all strings: grid file, 
      METCRO file, concentration file, retrieval and date list (from 
      makeRetList()), output .npz file name, and date of interest 
      (YYYYMMDD))

  Output
    .npz file
  """

  grid_file = fileDict['grid']
  metcro_file = fileDict['metcro']
  conc_file = fileDict['conc']
  ret_path = fileDict['retrievals']
  out_file = fileDict['out']
  model_date = fileDict['model_date']
  if type(model_date) is not str: model_date = str(model_date)

  # read in data/model output
  retDict = getRetData(model_date, retsDates=ret_path)
  retLats, retLons = retDict['lats'], retDict['lons']
  retP = retDict['pressure']
  mcDict = getMETCRO(metcro_file)
  gLat, gLon = getGrid(grid_file)
  concentration = getConcentration(conc_file)

  # find closest model grid point to each retrieval location
  idxCol, idxRow = [], []
  for rLat, rLon in zip(retLats, retLons):
    iRow, iCol = closestGridBox(gLat, gLon, rLat, rLon)
    idxCol.append(iCol)
    idxRow.append(iRow)
  # end grid

  # grab the model concentrations of interest
  modelDict = \
    getModelParams(idxRow, idxCol, concentration, mcDict)
  modelP = modelDict['pressure']
  modelConc = modelDict['concentration']

  interpModelConc = interpModel2Retrieval(retP, modelP, modelConc)
  #np.savez('debug_file', retDat=retDict, modelOut=modelDict, \
  #  modelInterp=interpModelConc)
  #sys.exit()

  modelRVMR, retRVMR = calcModelRVMR(retDict, interpModelConc)

  np.savez(out_file, retRVMR=retRVMR, modelRVMR=modelRVMR, \
    rLats=retLats, rLons=retLons, mLats=gLat, mLons=gLon, \
    retDict=retDict, modelDict=modelDict)

  return True
# end getVarsModRet()

envCAL = '/nas/CMAQ/CALNEX'
def campaignDataCrIS(cmaqDir='%s/CMAQ_OUTPUT' % envCAL, \
  mcipDir='%s/MCIP_OUTPUT' % envCAL, \
  retDir='/nas/project/p1913/cris_cal_2012_june_11_june_30/cdf_dir', \
  startDate='20120611', endDate='20120630'):

  """
  Determine CMAQ filenames for all of the files in the CALNEX campaign
  and find associated MCIP files and retrievals
  WARNING: may be obsolete since RLP restructured the code in Sep 2016

  Call

  Input

  Output
    cmaqFiles -- 
    grdFiles -- 
    mcipFiles -- 
    cDates -- 

  Keywords
    cmaqDir -- string, path to shared directory with CMAQ output files
    mcipDir -- string, path to shared directory with MCIP output files
    retDir -- string, path to shared directory with CrIS retrievals
    startDate -- string, YYYYMMDD that marks the start of the 
      retrieval period
    endDate -- string, YYYYMMDD that marks the end of the retrieval 
      period
  """

  utils.file_check(cmaqDir); utils.file_check(mcipDir)
  utils.file_check(retDir)

  cmd = 'ls %s/2012/CCTM_V5_0_1_saprc07tb_ae6_aq_VKB.CONC.*_VKB' % \
    cmaqDir
  cmaqFilesAll = utils.ls(cmd)

  tFormat = '%Y%m%d'
  startDT = DT.datetime.strptime(startDate, tFormat)
  endDT = DT.datetime.strptime(endDate, tFormat)

  # extract CMAQ dates from filenames
  cDates = []; cmaqFiles = []
  for cFile in cmaqFilesAll:
    # assuming CCTM_V5_0_1_saprc07tb_ae6_aq_VKB.CONC.YYYYMMDD_VKB 
    # naming convention
    base = os.path.basename(cFile)
    split = base.split('.')
    date = split[-1].split('_')
    dateDT = DT.datetime.strptime(date[0], tFormat)
    if (dateDT < startDT) or (dateDT > endDT): continue
    cDates.append(date[0])
    if date[0] in cFile: cmaqFiles.append(cFile)
  # end cFile loop

  # now get associated grid and MCIP files
  grdStr = '%s/2012/GRIDCRO2D_CALNEX_D03' % mcipDir
  mcipStr = '%s/2012/METCRO3D_CALNEX_D03' % mcipDir
  grdFiles = []; mcipFiles = []
  for date in cDates:
    mcipFile = '%s_%s' % (mcipStr, date)
    grdFile = '%s_%s' % (grdStr, date)
    if os.path.exists(mcipFile): mcipFiles.append(mcipFile)
    if os.path.exists(grdFile): grdFiles.append(grdFile)
  # end loop over dates

  return cmaqFiles, grdFiles, mcipFiles, cDates
# end campaignDataCrIS()

def getCampaignData(cmaq, grid, mcip, dates, retrieval_path, \
  nCores=4):
  """
  Multithread the getDataCrIS() process
  WARNING: may be obsolete since RLP restructured the code in Sep 2016

  Call

  Input
    cmaq -- list of strings, CMAQ output files
    grid -- list of strings, grid files
    mcip -- list of strings, MCIP files
      all three lists can be generated with campaignDataCrIS()
    retrieval_path -- string, full to retrievals

  Output

  Keywords
    nCores -- int, number of CPU cores to use

  """

  from multiprocessing import Pool, cpu_count, Process

  # assemble list of file dictionaries for getDataCrIS()
  dictList = []
  for cFile, gFile, mFile, date in zip(cmaq, grid, mcip, dates):
    outFile = 'CrIS_CMAQ_ObsOp_%s' % date
    inDict = {'grid': gFile, 'metcro': mFile, 'conc': cFile, \
      'out': outFile, 'retrievals': retrieval_path, 'model_date': date}
    dictList.append(inDict)
  # end loop over input files

  totCores = cpu_count()
  nCores = args.cores
  nCores = nCores if nCores < totCores else totCores-1

  p = Pool(nCores)
  p.map(getDataCrIS, dictList)

  return True
# end getCampaignData

def mapCMAQ_CrIS(cris_obs_op_plot, cmaq_obs_op_plot, \
  crisLats, crisLons, titleDate, outFile='CMAQ_temp.png'):
  # Plot RVMR

  def plotPanel(figObj, baseObj, iPanel, xScat, yScat, plotDat, \
    plotTitle, lWidth=0.5, cbarTitle='NH$_3$ ppbv', \
    scatMin=0, scatMax=5, diffPlot=False):

    ax = figObj.add_subplot(1, 3, iPanel)
    baseObj.scatter(xScat, yScat , marker='s', c=plotDat, \
      s=15, vmin=scatMin, vmax=scatMax)
    baseObj.drawcoastlines(linewidth=lWidth)
    baseObj.drawcountries(linewidth=lWidth)
    baseObj.drawstates(linewidth=lWidth)

    parallels = np.arange(0., 80, 5.)
    baseObj.drawparallels(parallels, labels=[1,0,0,1], \
      linewidth=lWidth)

    meridians = np.arange(10., 360., 5.)
    baseObj.drawmeridians(meridians, labels=[1,0,0,1])

    baseObj.fillcontinents(color='#cc9966', alpha=0.3)
    baseObj.drawmapboundary(fill_color='#99ffff')

    cbar = plt.colorbar(shrink=0.6)
    cbar.set_label(cbarTitle)
    plt.title(plotTitle)
    #plt.set_cmap('BlueRedAlpha') if diffPlot else plt.set_cmap('jet')
  # end plotPanel

  cdict3 = {'red':  ((0.0, 0.0, 0.0),
                     (0.25,0.0, 0.0),
                     (0.5, 0.8, 1.0),
                     (0.75,1.0, 1.0),
                     (1.0, 0.4, 1.0)),

       	   'green': ((0.0, 0.0, 0.0),
                     (0.25,0.0, 0.0),
                     (0.5, 0.9, 0.9),
                     (0.75,0.0, 0.0),
                     (1.0, 0.0, 0.0)),

        	   'blue':  ((0.0, 0.0, 0.4),
                     (0.25,1.0, 1.0),
                     (0.5, 1.0, 0.8),
                     (0.75,0.0, 0.0),
                     (1.0, 0.0, 0.0))
      	    }
  cdict4 = cdict3.copy()
	
  cdict4['alpha'] = ((0.0, 1.0, 1.0),
                     (0.5, 0.3, 0.3),
                     (1.0, 1.0, 1.0))

  #cMapDef = plt.get_cmap().name

  import matplotlib.pyplot as plt
  fig = plt.figure()
  fig.set_size_inches(11, 8.5)
  m = Basemap(llcrnrlon=-125, llcrnrlat=30., \
              urcrnrlon=-115., urcrnrlat=45, \
              lat_1=20., lat_2=40., lon_0=-60.,
              resolution ='l', area_thresh=1000., projection='cyl')
  x, y = m(crisLons, crisLats)

  #plt.register_cmap(name='BlueRedAlpha', data=cdict4)
  plotPanel(fig, m, 1, x, y, cris_obs_op_plot, 'CrIS\n%s' % \
    titleDate)
  plotPanel(fig, m, 2, x, y, cmaq_obs_op_plot, 'CMAQ\n%s' % \
    titleDate)
  plotPanel(fig, m, 3, x, y, cmaq_obs_op_plot-cris_obs_op_plot, \
    'CMAQ - CrIS\n%s' % titleDate, diffPlot=True, \
    cbarTitle='CMAQ - CrIS (ppbv)', scatMin=-3, scatMax=3)

  plt.savefig(outFile)
  plt.close()
# end mapCMAQ_CrIS()

def boxCMAQ_CrIS():
  """

  Call

  Input

  Output

  Keywords

  """

  return
# end boxCMAQ_CrIS()

def scatterCMAQ_CrIS(retRVMR, modelRVMR, date, molecule='NH$_3$', \
  model='CMAQ', instrument='CrIS', campaign='CalNex', \
  conMin=0, conMax=30, outFile=None):
  """
  Model-data retrieval comparison of molecule concentrations

  Call
    scatterCMAQ_CrIS(retRVMR, modelRVRM, date)

  Input
    retRVRM -- float array, representative volume mixing ratio from 
      retrievals
    modelRVRM -- float array, RVMR from model
    date -- string, YYYYMMDD of observations

  Output
    either Python plotting window or outFile (see keywords)

  Keywords
    molecule -- string, molecule representation
    model -- string, name of model used
    instrument -- string, name of instrument that made measurements 
      from which retrievals are based
    campaign -- string, name of data collection campaign
      (e.g., SENex or CalNex)
    conMin, conMax -- floats, minimum and maximum concentration values
      (for setting axes limits)
    outFile -- string, path for file to which plot is saved (default 
      is not to save plot but display in plotting window)
  """

  # best fit line representation
  coeff = np.polyfit(retRVMR, modelRVMR, 1)
  fit = np.poly1d(coeff)

  lims = [conMin, conMax]
  plt.plot(retRVMR, modelRVMR, 'ro', retRVMR, fit(retRVMR), 'b')
  plt.xlim(lims)
  plt.ylim(lims)

  # extract limits from axes so we can do a y=x line
  ax = plt.gca()
  xlim = ax.get_xlim()
  ylim = ax.get_ylim()
  plt.plot(xlim, ylim, 'k--')

  plt.xlabel('$_{%s}$ %s (ppbv)' % (instrument, molecule))
  plt.ylabel('$_{%s}$ %s (ppbv)' % (model, molecule))
  plt.title('%s Concentrations, %s, %s' % (molecule, date, campaign))
  plt.savefig(outFile) if outFile else plt.show()
  plt.close()

  return
# end scatterCMAQ_CrIS()

if __name__ == '__main__':

  parser = argparse.ArgumentParser(\
    description='CMAQ NH3 vs. retrieval plotting. Adapted from ' + \
    'Chantelle Lonsdale code.')
  parser.add_argument('--date', type=str, default='20120612', \
    help='Date of interest, in the form of a YYYYMMDD string.')
  parser.add_argument('--CMAQ_output_dir', type=str, \
    default='/nas/CMAQ/CALNEX/CMAQ_OUTPUT', \
    help='Path to shared directory with CMAQ output files.')
  parser.add_argument('--MCIP_output_dir', type=str, \
    default='/nas/CMAQ/CALNEX/MCIP_OUTPUT', \
    help='Path to shared directory with MCIP output files.')
  parser.add_argument('--retrieval_list', type=str, \
    default='retrieval_dates_CalNex.txt', \
    help='Path to ASCII list with CrIS retrievals and associated ' + \
    'dates (probably made with makeRetList() function).')
  parser.add_argument('--getData', action='store_true', \
    help='If set, loads CrIS retrievals. Otherwise, plots the ' + \
    'data from a save file.')
  parser.add_argument('--savefile', type=str, \
    default='CrIS_CMAQ.npz', \
    help='Save file to which CrIS data are saved (since they are ' + 
      'so time-consuming to load. With --getData, the data are ' + \
      'saved to this path. Without it, the data are loaded).')
  parser.add_argument('--campaign', action='store_true', \
    help='Separate from other keywords. If set, do a getData ' + \
    'for the entire CALNEX campaign rather than just 1 day.')
  parser.add_argument('--cores', type=int, default=4, \
    help='Number of cores to use with --campaign')
  args = parser.parse_args()

  cmaq_date = args.date
  retPath = args.retrieval_list; utils.file_check(retPath)

  if args.campaign:
    cFiles, gFiles, mFiles, dates = campaignDataCrIS()

    # single-case (multithread test)
    #inFiles = {'grid': gFiles[0], 'metcro': mFiles[0], \
    #  'conc': cFiles[0], 'out': args.savefile, 'retrievals': retPath, \
    #  'model_date': dates[0]}
    #getDataCrIS(inFiles)
    getCampaignData(cFiles, gFiles, mFiles, dates, retPath)

    sys.exit('Finished CALNEX data grab')
  # end campaign

  ################################
  # --- get CrIS data  ---
  ################################
  if args.getData:
    # make sure date is acceptable format
    try:
      tFormat = '%Y%m%d'
      cmaqDT = DT.datetime.strptime(cmaq_date, tFormat)
      year = cmaqDT.year
    except:
      sys.exit('Please enter a date with the form YYYYMMDD')
    # end exception

    mDir = args.MCIP_output_dir; utils.file_check(mDir)
    cDir = args.CMAQ_output_dir; utils.file_check(cDir)

    gFile = '%s/%4d/GRIDCRO2D_CALNEX_D03_%s' % (mDir, year, cmaq_date)
    mFile = '%s/%4d/METCRO3D_CALNEX_D03_%s' % (mDir, year, cmaq_date)
    cFile = '%s/%4d/CCTM_V5_0_1_saprc07tb_ae6_aq_VKB.CONC.%s_VKB' % \
      (cDir, year, cmaq_date)
    utils.file_check(gFile); utils.file_check(mFile)
    utils.file_check(cFile)

    inFiles = {'grid': gFile, 'metcro': mFile, 'conc': cFile, \
      'out': args.savefile, 'retrievals': retPath, \
      'model_date': cmaq_date}
    getVarsModRet(inFiles)
  # end getData

  #############################################################
  # Plot CMAQ and CrIS retrievals
  #############################################################

  datLoad = np.load(args.savefile)
  crisObsOpArr = datLoad['retRVMR']
  cmaqObsOpArr = datLoad['modelRVMR']
  cLats = datLoad['rLats']; cLons = datLoad['rLons']
  mapCMAQ_CrIS(crisObsOpArr, cmaqObsOpArr, cLats, cLons, cmaq_date)

# end main()

